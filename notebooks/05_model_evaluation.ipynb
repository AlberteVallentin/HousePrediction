{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 05: Test Set Evaluation and Final Deployment\n",
    "\n",
    "Test set evaluation using optimized ensemble model from notebook 04 for final prediction generation and deployment preparation.\n",
    "Model validation on holdout test data with performance assessment and competition submission file creation for deployment readiness.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Load Optimized Model and Test Data Preparation\n",
    "\n",
    "THIS DEPENDS ON SECTION 6 FROM NOTEBOOK 04\n",
    "\n",
    "Load optimized ensemble model from notebook 04 and prepare test dataset for final prediction generation.\n",
    "Validate model consistency and feature alignment while ensuring reproducible prediction pipeline for deployment.\n",
    "\n",
    "### 1.1 Model Import and Test Data Loading\n",
    "\n",
    "Load optimized ensemble model from notebook 04 and prepare feature-engineered test dataset for final predictions.\n",
    "Validate 275 feature consistency and model component alignment for reproducible prediction generation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset shape: (1459, 276)\n",
      "Test features shape: (1459, 275)\n",
      "Test feature count: 275\n",
      "Test sample count: 1459\n",
      "Missing values in test: 0\n",
      "✗ Model loading failed: [Errno 2] No such file or directory: '../models/elastic_net_optimized.pkl'\n",
      "Please ensure notebook 04 Section 6 has been completed\n"
     ]
    }
   ],
   "source": [
    "# Load required libraries for test evaluation and deployment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load feature-engineered test dataset from notebook 03\n",
    "df_test_engineered = pd.read_csv('../data/processed/test_feature_engineered.csv')\n",
    "print(f\"Test dataset shape: {df_test_engineered.shape}\")\n",
    "\n",
    "# Prepare test features (same 275 features from training)\n",
    "feature_cols = [col for col in df_test_engineered.columns \n",
    "                if col not in ['Id', 'SalePrice', 'SalePrice_log']]\n",
    "X_test = df_test_engineered[feature_cols]\n",
    "test_ids = df_test_engineered['Id']\n",
    "\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "print(f\"Test feature count: {len(feature_cols)}\")\n",
    "print(f\"Test sample count: {len(test_ids)}\")\n",
    "print(f\"Missing values in test: {X_test.isnull().sum().sum()}\")\n",
    "\n",
    "# Load optimized models from notebook 04\n",
    "try:\n",
    "    # Load individual optimized models (all 4 from Section 6)\n",
    "    elastic_net_optimized = joblib.load('../models/elastic_net_optimized.pkl')\n",
    "    xgboost_optimized = joblib.load('../models/xgboost_optimized.pkl')\n",
    "    lightgbm_optimized = joblib.load('../models/lightgbm_optimized.pkl')\n",
    "    catboost_optimized = joblib.load('../models/catboost_optimized.pkl')\n",
    "    \n",
    "    # Load ensemble model and weights\n",
    "    ensemble_weights = joblib.load('../models/ensemble_weights_optimized.pkl')\n",
    "    scaler = joblib.load('../models/scaler_ensemble.pkl')\n",
    "    \n",
    "    print(f\"✓ Models loaded successfully\")\n",
    "    print(f\"✓ Ensemble weights: {ensemble_weights}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"✗ Model loading failed: {e}\")\n",
    "    print(\"Please ensure notebook 04 Section 6 has been completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model loading confirms optimized ensemble availability with consistent feature alignment for test evaluation.\n",
    "Preprocessing pipeline validation ensures reproducible prediction generation using notebook 04 optimization results.\n",
    "\n",
    "### 1.2 Model Validation and Feature Consistency Check\n",
    "\n",
    "Validate loaded models against test dataset features and verify prediction pipeline consistency.\n",
    "Ensure feature alignment and model component integrity before generating final test predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature validation for model deployment:\n",
      "Expected features: 275\n",
      "Actual features: 275\n",
      "Feature count validation: ✓ PASSED\n",
      "Missing values in test: 0\n",
      "Missing value validation: ✓ PASSED\n",
      "✓ Model prediction test successful\n",
      "Sample predictions (log scale):\n",
      "  Elastic Net: 11.6604\n",
      "  XGBoost: 11.7631\n",
      "  LightGBM: 11.7329\n",
      "  CatBoost: 11.7486\n",
      "  Ensemble: 11.7241\n"
     ]
    }
   ],
   "source": [
    "# Validate feature consistency between training and test\n",
    "print(\"Feature validation for model deployment:\")\n",
    "\n",
    "# Check feature count consistency\n",
    "expected_features = 275\n",
    "actual_features = len(feature_cols)\n",
    "print(f\"Expected features: {expected_features}\")\n",
    "print(f\"Actual features: {actual_features}\")\n",
    "print(f\"Feature count validation: {'✓ PASSED' if actual_features == expected_features else '✗ FAILED'}\")\n",
    "\n",
    "# Verify no missing values in test set\n",
    "missing_count = X_test.isnull().sum().sum()\n",
    "print(f\"Missing values in test: {missing_count}\")\n",
    "print(f\"Missing value validation: {'✓ PASSED' if missing_count == 0 else '✗ FAILED'}\")\n",
    "\n",
    "# Test model prediction capability with first sample\n",
    "try:\n",
    "    # Scale test data for Elastic Net\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Generate predictions from each model component\n",
    "    pred_elastic = elastic_net_optimized.predict(X_test_scaled[:1])\n",
    "    pred_xgboost = xgboost_optimized.predict(X_test[:1])\n",
    "    pred_lightgbm = lightgbm_optimized.predict(X_test[:1])\n",
    "    pred_catboost = catboost_optimized.predict(X_test[:1])\n",
    "    \n",
    "    print(f\"✓ Model prediction test successful\")\n",
    "    print(f\"Sample predictions (log scale):\")\n",
    "    print(f\"  Elastic Net: {pred_elastic[0]:.4f}\")\n",
    "    print(f\"  XGBoost: {pred_xgboost[0]:.4f}\")\n",
    "    print(f\"  LightGBM: {pred_lightgbm[0]:.4f}\")\n",
    "    print(f\"  CatBoost: {pred_catboost[0]:.4f}\")\n",
    "    \n",
    "    # Test ensemble prediction with all 4 models\n",
    "    ensemble_pred = (ensemble_weights[0] * pred_elastic[0] + \n",
    "                    ensemble_weights[1] * pred_xgboost[0] + \n",
    "                    ensemble_weights[2] * pred_lightgbm[0] +\n",
    "                    ensemble_weights[3] * pred_catboost[0])\n",
    "    print(f\"  Ensemble: {ensemble_pred:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Model prediction test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model validation confirms prediction pipeline integrity with consistent feature processing and ensemble weighting.\n",
    "Individual model components demonstrate successful prediction capability on test dataset sample validation.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Test Set Prediction Generation\n",
    "\n",
    "Generate final predictions using optimized ensemble model for test dataset evaluation and submission preparation.\n",
    "Apply consistent preprocessing and ensemble weighting from notebook 04 optimization for deployment-ready predictions.\n",
    "\n",
    "### 2.1 Individual Model Predictions on Test Set\n",
    "\n",
    "Generate predictions from each optimized model component on full test dataset for ensemble combination.\n",
    "Apply consistent scaling and preprocessing pipeline to ensure prediction quality and model performance consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test set predictions from individual models:\n",
      "✓ Elastic Net predictions generated: 1459 samples\n",
      "✓ XGBoost predictions generated: 1459 samples\n",
      "✓ LightGBM predictions generated: 1459 samples\n",
      "✓ CatBoost predictions generated: 1459 samples\n",
      "\n",
      "Prediction statistics (log scale):\n",
      "Elastic Net - Mean: 12.0121, Std: 0.3889\n",
      "XGBoost - Mean: 12.0114, Std: 0.3967\n",
      "LightGBM - Mean: 12.0096, Std: 0.3919\n",
      "CatBoost - Mean: 12.0124, Std: 0.3961\n",
      "\n",
      "Prediction range validation:\n",
      "Elastic Net: Min=10.8986, Max=14.2711\n",
      "✓ Elastic Net predictions within expected range\n",
      "XGBoost: Min=10.7169, Max=13.4407\n",
      "✓ XGBoost predictions within expected range\n",
      "LightGBM: Min=10.7664, Max=13.3470\n",
      "✓ LightGBM predictions within expected range\n",
      "CatBoost: Min=10.7217, Max=13.4131\n",
      "✓ CatBoost predictions within expected range\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions from individual optimized models\n",
    "print(\"Generating test set predictions from individual models:\")\n",
    "\n",
    "# Elastic Net predictions (requires scaled features)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "test_pred_elastic = elastic_net_optimized.predict(X_test_scaled)\n",
    "print(f\"✓ Elastic Net predictions generated: {len(test_pred_elastic)} samples\")\n",
    "\n",
    "# XGBoost predictions (uses original features)\n",
    "test_pred_xgboost = xgboost_optimized.predict(X_test)\n",
    "print(f\"✓ XGBoost predictions generated: {len(test_pred_xgboost)} samples\")\n",
    "\n",
    "# LightGBM predictions (uses original features)\n",
    "test_pred_lightgbm = lightgbm_optimized.predict(X_test)\n",
    "print(f\"✓ LightGBM predictions generated: {len(test_pred_lightgbm)} samples\")\n",
    "\n",
    "# CatBoost predictions (uses original features)\n",
    "test_pred_catboost = catboost_optimized.predict(X_test)\n",
    "print(f\"✓ CatBoost predictions generated: {len(test_pred_catboost)} samples\")\n",
    "\n",
    "# Prediction statistics for quality assessment\n",
    "print(f\"\\nPrediction statistics (log scale):\")\n",
    "print(f\"Elastic Net - Mean: {test_pred_elastic.mean():.4f}, Std: {test_pred_elastic.std():.4f}\")\n",
    "print(f\"XGBoost - Mean: {test_pred_xgboost.mean():.4f}, Std: {test_pred_xgboost.std():.4f}\")\n",
    "print(f\"LightGBM - Mean: {test_pred_lightgbm.mean():.4f}, Std: {test_pred_lightgbm.std():.4f}\")\n",
    "print(f\"CatBoost - Mean: {test_pred_catboost.mean():.4f}, Std: {test_pred_catboost.std():.4f}\")\n",
    "\n",
    "# Check for any prediction anomalies\n",
    "print(f\"\\nPrediction range validation:\")\n",
    "for name, preds in [(\"Elastic Net\", test_pred_elastic), \n",
    "                   (\"XGBoost\", test_pred_xgboost),\n",
    "                   (\"LightGBM\", test_pred_lightgbm),\n",
    "                   (\"CatBoost\", test_pred_catboost)]:\n",
    "    min_pred, max_pred = preds.min(), preds.max()\n",
    "    print(f\"{name}: Min={min_pred:.4f}, Max={max_pred:.4f}\")\n",
    "    \n",
    "    # Check for unrealistic predictions (log scale should be ~10-14)\n",
    "    if min_pred < 8 or max_pred > 15:\n",
    "        print(f\"⚠ Warning: {name} predictions outside expected range\")\n",
    "    else:\n",
    "        print(f\"✓ {name} predictions within expected range\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual model predictions generated successfully with consistent preprocessing and validation checks.\n",
    "Prediction range validation confirms realistic price estimates within expected market value boundaries for deployment.\n",
    "\n",
    "### 2.2 Ensemble Prediction Generation and Validation\n",
    "\n",
    "Combine individual model predictions using optimized ensemble weights for final test set evaluation.\n",
    "Generate deployment-ready predictions with quality validation and original price scale conversion for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating optimized ensemble predictions:\n",
      "Using ensemble weights: [0.3017775402566104, 0.27841093054122185, 0.12004286912192369, 0.29976866008024405]\n",
      "✓ Ensemble predictions generated: 1459 samples\n",
      "\n",
      "Ensemble prediction statistics:\n",
      "Log scale - Mean: 12.0117, Std: 0.3924\n",
      "Original scale - Mean: $178,614, Std: $79,748\n",
      "Price range: $49,652 - $866,111\n",
      "\n",
      "Prediction summary shape: (1459, 7)\n",
      "Sample predictions:\n",
      "     Id  Ensemble_Log      SalePrice\n",
      "0  1461     11.724121  123515.337029\n",
      "1  1462     11.986232  160529.305860\n",
      "2  1463     12.106218  180993.833380\n",
      "3  1464     12.166516  192243.137678\n",
      "4  1465     12.167600  192451.656529\n",
      "5  1466     12.076372  175671.674393\n",
      "6  1467     12.073346  175140.864740\n",
      "7  1468     12.031552  167971.967644\n",
      "8  1469     12.145674  188277.912317\n",
      "9  1470     11.733481  124676.948170\n",
      "\n",
      "Prediction validation:\n",
      "All predictions positive: True\n",
      "No infinite/NaN values: True\n",
      "Realistic price range: True\n"
     ]
    }
   ],
   "source": [
    "# Generate ensemble predictions using optimized weights\n",
    "print(\"Generating optimized ensemble predictions:\")\n",
    "print(f\"Using ensemble weights: {ensemble_weights}\")\n",
    "\n",
    "# Combine predictions using optimized weights (4 models)\n",
    "test_pred_ensemble_log = (ensemble_weights[0] * test_pred_elastic + \n",
    "                         ensemble_weights[1] * test_pred_xgboost + \n",
    "                         ensemble_weights[2] * test_pred_lightgbm +\n",
    "                         ensemble_weights[3] * test_pred_catboost)\n",
    "\n",
    "print(f\"✓ Ensemble predictions generated: {len(test_pred_ensemble_log)} samples\")\n",
    "\n",
    "# Convert to original price scale for submission\n",
    "test_pred_ensemble = np.exp(test_pred_ensemble_log)\n",
    "\n",
    "# Prediction quality assessment\n",
    "print(f\"\\nEnsemble prediction statistics:\")\n",
    "print(f\"Log scale - Mean: {test_pred_ensemble_log.mean():.4f}, Std: {test_pred_ensemble_log.std():.4f}\")\n",
    "print(f\"Original scale - Mean: ${test_pred_ensemble.mean():,.0f}, Std: ${test_pred_ensemble.std():,.0f}\")\n",
    "print(f\"Price range: ${test_pred_ensemble.min():,.0f} - ${test_pred_ensemble.max():,.0f}\")\n",
    "\n",
    "# Create prediction summary dataframe\n",
    "prediction_summary = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'Elastic_Net_Log': test_pred_elastic,\n",
    "    'XGBoost_Log': test_pred_xgboost,\n",
    "    'LightGBM_Log': test_pred_lightgbm,\n",
    "    'CatBoost_Log': test_pred_catboost,\n",
    "    'Ensemble_Log': test_pred_ensemble_log,\n",
    "    'SalePrice': test_pred_ensemble\n",
    "})\n",
    "\n",
    "print(f\"\\nPrediction summary shape: {prediction_summary.shape}\")\n",
    "print(f\"Sample predictions:\")\n",
    "print(prediction_summary[['Id', 'Ensemble_Log', 'SalePrice']].head(10))\n",
    "\n",
    "# Validate prediction consistency\n",
    "print(f\"\\nPrediction validation:\")\n",
    "print(f\"All predictions positive: {(test_pred_ensemble > 0).all()}\")\n",
    "print(f\"No infinite/NaN values: {np.isfinite(test_pred_ensemble).all()}\")\n",
    "print(f\"Realistic price range: {(test_pred_ensemble >= 10000).all() and (test_pred_ensemble <= 1000000).all()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble predictions generated with optimized weighting demonstrating realistic price distributions and quality validation.\n",
    "Final predictions ready for competition submission with comprehensive quality checks and original price scale conversion.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Submission File Creation and Model Deployment\n",
    "\n",
    "Create competition submission file and prepare model artifacts for deployment and future predictions.\n",
    "Generate final deliverables with prediction validation and model export for production readiness assessment.\n",
    "\n",
    "### 3.1 Competition Submission File Generation\n",
    "\n",
    "Create properly formatted submission file for competition evaluation with prediction validation and quality checks.\n",
    "Generate CSV output matching competition requirements while maintaining prediction quality and format compliance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file preparation:\n",
      "Submission shape: (1459, 2)\n",
      "Required format: Id, SalePrice columns\n",
      "\n",
      "Submission validation:\n",
      "✓ Id column present: True\n",
      "✓ SalePrice column present: True\n",
      "✓ Correct sample count: True\n",
      "✓ No missing predictions: True\n",
      "✓ Id range validation: True\n",
      "\n",
      "Submission statistics:\n",
      "Price range: $49,652 - $866,111\n",
      "Mean price: $178,614\n",
      "Median price: $156,139\n",
      "✓ Submission saved: ../submissions/submission_ensemble_optimized.csv\n",
      "\n",
      "Submission sample:\n",
      "     Id      SalePrice\n",
      "0  1461  123515.337029\n",
      "1  1462  160529.305860\n",
      "2  1463  180993.833380\n",
      "3  1464  192243.137678\n",
      "4  1465  192451.656529\n",
      "5  1466  175671.674393\n",
      "6  1467  175140.864740\n",
      "7  1468  167971.967644\n",
      "8  1469  188277.912317\n",
      "9  1470  124676.948170\n"
     ]
    }
   ],
   "source": [
    "# Create competition submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'SalePrice': test_pred_ensemble\n",
    "})\n",
    "\n",
    "print(f\"Submission file preparation:\")\n",
    "print(f\"Submission shape: {submission_df.shape}\")\n",
    "print(f\"Required format: Id, SalePrice columns\")\n",
    "\n",
    "# Validate submission format\n",
    "print(f\"\\nSubmission validation:\")\n",
    "print(f\"✓ Id column present: {'Id' in submission_df.columns}\")\n",
    "print(f\"✓ SalePrice column present: {'SalePrice' in submission_df.columns}\")\n",
    "print(f\"✓ Correct sample count: {len(submission_df) == len(test_ids)}\")\n",
    "print(f\"✓ No missing predictions: {submission_df['SalePrice'].isnull().sum() == 0}\")\n",
    "\n",
    "# Check Id consistency\n",
    "expected_ids = range(1461, 2920)  # Test set Id range\n",
    "actual_ids = sorted(submission_df['Id'].values)\n",
    "print(f\"✓ Id range validation: {actual_ids == list(expected_ids)}\")\n",
    "\n",
    "# Display submission statistics\n",
    "print(f\"\\nSubmission statistics:\")\n",
    "print(f\"Price range: ${submission_df['SalePrice'].min():,.0f} - ${submission_df['SalePrice'].max():,.0f}\")\n",
    "print(f\"Mean price: ${submission_df['SalePrice'].mean():,.0f}\")\n",
    "print(f\"Median price: ${submission_df['SalePrice'].median():,.0f}\")\n",
    "\n",
    "# Save submission file\n",
    "submission_file = '../submissions/submission_ensemble_optimized.csv'\n",
    "submission_df.to_csv(submission_file, index=False)\n",
    "print(f\"✓ Submission saved: {submission_file}\")\n",
    "\n",
    "# Display sample of submission\n",
    "print(f\"\\nSubmission sample:\")\n",
    "print(submission_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating individual model submission:\n",
      "Using Elastic Net (best individual CV: 0.1148)\n",
      "\n",
      "Individual model submission preparation:\n",
      "Submission shape: (1459, 2)\n",
      "Model: Elastic Net (optimized)\n",
      "\n",
      "Individual submission validation:\n",
      "✓ Id column present: True\n",
      "✓ SalePrice column present: True\n",
      "✓ Correct sample count: True\n",
      "✓ No missing predictions: True\n",
      "\n",
      "Individual vs Ensemble Comparison:\n",
      "Individual (Elastic Net) - Mean: $178,635, Std: $84,045\n",
      "Ensemble (4-model) - Mean: $178,614, Std: $79,748\n",
      "Price range individual: $54,100 - $1,577,151\n",
      "Price range ensemble: $49,652 - $866,111\n",
      "✓ Individual submission saved: ../submissions/submission_elastic_net_individual.csv\n",
      "\n",
      "Submission comparison sample:\n",
      "     Id  Individual_ElasticNet  Ensemble_4Model   Difference\n",
      "0  1461          115886.292789    123515.337029  7629.044240\n",
      "1  1462          157933.192620    160529.305860  2596.113239\n",
      "2  1463          181781.397562    180993.833380  -787.564182\n",
      "3  1464          194787.547812    192243.137678 -2544.410133\n",
      "4  1465          194732.559680    192451.656529 -2280.903150\n",
      "5  1466          172173.084368    175671.674393  3498.590025\n",
      "6  1467          182756.584998    175140.864740 -7615.720257\n",
      "7  1468          162764.284499    167971.967644  5207.683145\n",
      "8  1469          191626.545438    188277.912317 -3348.633121\n",
      "9  1470          119358.951459    124676.948170  5317.996711\n"
     ]
    }
   ],
   "source": [
    "# Generate submission using best individual model (Elastic Net)\n",
    "print(\"Generating individual model submission:\")\n",
    "print(\"Using Elastic Net (best individual CV: 0.1148)\")\n",
    "\n",
    "# Convert Elastic Net predictions to original scale\n",
    "test_pred_elastic_original = np.exp(test_pred_elastic)\n",
    "\n",
    "# Create individual model submission\n",
    "individual_submission_df = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'SalePrice': test_pred_elastic_original\n",
    "})\n",
    "\n",
    "print(f\"\\nIndividual model submission preparation:\")\n",
    "print(f\"Submission shape: {individual_submission_df.shape}\")\n",
    "print(f\"Model: Elastic Net (optimized)\")\n",
    "\n",
    "# Validate individual submission format\n",
    "print(f\"\\nIndividual submission validation:\")\n",
    "print(f\"✓ Id column present: {'Id' in individual_submission_df.columns}\")\n",
    "print(f\"✓ SalePrice column present: {'SalePrice' in individual_submission_df.columns}\")\n",
    "print(f\"✓ Correct sample count: {len(individual_submission_df) == len(test_ids)}\")\n",
    "print(f\"✓ No missing predictions: {individual_submission_df['SalePrice'].isnull().sum() == 0}\")\n",
    "\n",
    "# Compare individual vs ensemble predictions\n",
    "print(f\"\\nIndividual vs Ensemble Comparison:\")\n",
    "print(f\"Individual (Elastic Net) - Mean: ${test_pred_elastic_original.mean():,.0f}, Std: ${test_pred_elastic_original.std():,.0f}\")\n",
    "print(f\"Ensemble (4-model) - Mean: ${test_pred_ensemble.mean():,.0f}, Std: ${test_pred_ensemble.std():,.0f}\")\n",
    "print(f\"Price range individual: ${test_pred_elastic_original.min():,.0f} - ${test_pred_elastic_original.max():,.0f}\")\n",
    "print(f\"Price range ensemble: ${test_pred_ensemble.min():,.0f} - ${test_pred_ensemble.max():,.0f}\")\n",
    "\n",
    "# Save individual model submission\n",
    "individual_submission_file = '../submissions/submission_elastic_net_individual.csv'\n",
    "individual_submission_df.to_csv(individual_submission_file, index=False)\n",
    "print(f\"✓ Individual submission saved: {individual_submission_file}\")\n",
    "\n",
    "# Display sample comparison\n",
    "print(f\"\\nSubmission comparison sample:\")\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Id': test_ids[:10],\n",
    "    'Individual_ElasticNet': test_pred_elastic_original[:10],\n",
    "    'Ensemble_4Model': test_pred_ensemble[:10],\n",
    "    'Difference': test_pred_ensemble[:10] - test_pred_elastic_original[:10]\n",
    "})\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Competition submission file created with format validation and quality checks ensuring competition compliance.\n",
    "Final predictions exported with comprehensive validation demonstrating deployment readiness and submission quality.\n",
    "\n",
    "### 3.2 Model Export and Deployment Preparation\n",
    "\n",
    "Export complete model pipeline and prediction artifacts for future deployment and production use.\n",
    "Save ensemble configuration and preprocessing components for reproducible prediction generation in production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing model artifacts for deployment:\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '../predictions'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      5\u001b[39m detailed_predictions = pd.DataFrame({\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mId\u001b[39m\u001b[33m'\u001b[39m: test_ids,\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mElastic_Net_Log\u001b[39m\u001b[33m'\u001b[39m: test_pred_elastic,\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPrediction_Date\u001b[39m\u001b[33m'\u001b[39m: pd.Timestamp.now().strftime(\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     14\u001b[39m })\n\u001b[32m     16\u001b[39m detailed_file = \u001b[33m'\u001b[39m\u001b[33m../predictions/test_predictions_detailed.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mdetailed_predictions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetailed_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✓ Detailed predictions saved: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdetailed_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Save ensemble configuration for deployment\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/HousePrediction/.venv/lib/python3.13/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/HousePrediction/.venv/lib/python3.13/site-packages/pandas/core/generic.py:3986\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3975\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3977\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3978\u001b[39m     frame=df,\n\u001b[32m   3979\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3983\u001b[39m     decimal=decimal,\n\u001b[32m   3984\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3988\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/HousePrediction/.venv/lib/python3.13/site-packages/pandas/io/formats/format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/HousePrediction/.venv/lib/python3.13/site-packages/pandas/io/formats/csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/HousePrediction/.venv/lib/python3.13/site-packages/pandas/io/common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/HousePrediction/.venv/lib/python3.13/site-packages/pandas/io/common.py:616\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: '../predictions'"
     ]
    }
   ],
   "source": [
    "# Export complete model pipeline for deployment\n",
    "print(\"Preparing model artifacts for deployment:\")\n",
    "\n",
    "# Save detailed prediction breakdown for analysis\n",
    "detailed_predictions = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'Elastic_Net_Log': test_pred_elastic,\n",
    "    'XGBoost_Log': test_pred_xgboost,\n",
    "    'CatBoost_Log': test_pred_catboost,\n",
    "    'Ensemble_Log': test_pred_ensemble_log,\n",
    "    'SalePrice_Predicted': test_pred_ensemble,\n",
    "    'Model_Version': 'Ensemble_Optimized_V1',\n",
    "    'Prediction_Date': pd.Timestamp.now().strftime('%Y-%m-%d')\n",
    "})\n",
    "\n",
    "detailed_file = '../predictions/test_predictions_detailed.csv'\n",
    "detailed_predictions.to_csv(detailed_file, index=False)\n",
    "print(f\"✓ Detailed predictions saved: {detailed_file}\")\n",
    "\n",
    "# Save ensemble configuration for deployment\n",
    "ensemble_config = {\n",
    "    'model_version': 'Ensemble_Optimized_V1',\n",
    "    'feature_count': len(feature_cols),\n",
    "    'ensemble_weights': ensemble_weights.tolist(),\n",
    "    'model_components': ['elastic_net_optimized', 'xgboost_optimized', 'catboost_optimized'],\n",
    "    'scaling_required': 'elastic_net_only',\n",
    "    'cv_rmse_performance': 0.1139,  # From notebook 04 Section 6\n",
    "    'created_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "import json\n",
    "config_file = '../models/ensemble_config.json'\n",
    "with open(config_file, 'w') as f:\n",
    "    json.dump(ensemble_config, f, indent=2)\n",
    "print(f\"✓ Ensemble configuration saved: {config_file}\")\n",
    "\n",
    "# Create deployment summary\n",
    "deployment_summary = f\"\"\"\n",
    "Model Deployment Summary\n",
    "========================\n",
    "Model Version: {ensemble_config['model_version']}\n",
    "Performance: {ensemble_config['cv_rmse_performance']} CV RMSE (log scale)\n",
    "Feature Count: {ensemble_config['feature_count']}\n",
    "Ensemble Weights: {ensemble_config['ensemble_weights']}\n",
    "\n",
    "Files Created:\n",
    "- Competition submission: {submission_file}\n",
    "- Detailed predictions: {detailed_file}\n",
    "- Model configuration: {config_file}\n",
    "\n",
    "Deployment Status: READY\n",
    "Model Quality: VALIDATED\n",
    "Prediction Range: ${submission_df['SalePrice'].min():,.0f} - ${submission_df['SalePrice'].max():,.0f}\n",
    "\"\"\"\n",
    "\n",
    "print(deployment_summary)\n",
    "\n",
    "# Save deployment summary\n",
    "summary_file = '../models/deployment_summary.txt'\n",
    "with open(summary_file, 'w') as f:\n",
    "    f.write(deployment_summary)\n",
    "print(f\"✓ Deployment summary saved: {summary_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
