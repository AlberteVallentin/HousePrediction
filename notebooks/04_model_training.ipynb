{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 04: Model Training and Comparison\n",
    "\n",
    "Systematic implementation of comprehensive model training and comparison methodology for evidence-based machine learning evaluation.\n",
    "Algorithm selection and performance optimization applied to feature-engineered datasets for competitive model development.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Load Preprocessed Data and Baseline Establishment\n",
    "\n",
    "THIS DEPENDS ON SECTION 7 FROM NOTEBOOK 03\n",
    "\n",
    "Load feature-engineered datasets and establish baseline performance metrics for model comparison framework.\n",
    "Validate data consistency and feature count alignment with notebook 03 preprocessing pipeline outputs.\n",
    "\n",
    "### 1.1 Dataset Import and Validation\n",
    "\n",
    "Load feature-engineered datasets from notebook 03 and establish performance baseline for systematic model comparison.\n",
    "Validate 275 features and SalePrice_log target consistency while creating train/validation splits for cross-validation framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature-engineered dataset shapes:\n",
      "Train: (1458, 278)\n",
      "Test: (1459, 276)\n",
      "\n",
      "Data quality verification:\n",
      "Train missing values: 0\n",
      "Test missing values: 0\n",
      "\n",
      "Feature validation:\n",
      "Features available: 275\n",
      "Expected from NB03: 275 features (excluding Id)\n",
      "Feature count validation: PASSED\n",
      "Target variables available: ['SalePrice', 'SalePrice_log']\n"
     ]
    }
   ],
   "source": [
    "# Load required libraries for model development and evaluation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load feature-engineered datasets from notebook 03\n",
    "df_train_engineered = pd.read_csv('../data/processed/train_feature_engineered.csv')\n",
    "df_test_engineered = pd.read_csv('../data/processed/test_feature_engineered.csv')\n",
    "\n",
    "print(\"Feature-engineered dataset shapes:\")\n",
    "print(f\"Train: {df_train_engineered.shape}\")\n",
    "print(f\"Test: {df_test_engineered.shape}\")\n",
    "\n",
    "# Verify data quality and consistency from feature engineering\n",
    "print(f\"\\nData quality verification:\")\n",
    "print(f\"Train missing values: {df_train_engineered.isnull().sum().sum()}\")\n",
    "print(f\"Test missing values: {df_test_engineered.isnull().sum().sum()}\")\n",
    "\n",
    "# Feature count validation against notebook 03 expectations\n",
    "feature_cols = [col for col in df_train_engineered.columns \n",
    "                if col not in ['SalePrice', 'SalePrice_log', 'Id']]\n",
    "print(f\"\\nFeature validation:\")\n",
    "print(f\"Features available: {len(feature_cols)}\")\n",
    "print(f\"Expected from NB03: 275 features (excluding Id)\")\n",
    "print(f\"Feature count validation: {'PASSED' if len(feature_cols) == 275 else 'REVIEW'}\")\n",
    "\n",
    "# Verify target variables from notebook 03 preprocessing\n",
    "target_cols = [col for col in df_train_engineered.columns if 'SalePrice' in col]\n",
    "print(f\"Target variables available: {target_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset loading confirms 275 engineered features with zero missing values and dual target variable availability.\n",
    "Feature matrix preparation enables systematic model development with validated preprocessing pipeline outputs.\n",
    "\n",
    "### 1.2 Baseline Performance Establishment and Target Preparation\n",
    "\n",
    "Establish baseline performance metrics using simple mean prediction for model comparison framework.\n",
    "Create train/validation splits with SalePrice_log as primary target following notebook 03 optimization results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shapes:\n",
      "X_train: (1458, 275)\n",
      "X_test: (1459, 275)\n",
      "y_train_original: (1458,)\n",
      "y_train_log: (1458,) (primary target - pre-optimized)\n",
      "\n",
      "Train/validation split:\n",
      "X_train_split: (1166, 275)\n",
      "X_val_split: (292, 275)\n",
      "y_train_split: (1166,)\n",
      "y_val_split: (292,)\n",
      "\n",
      "Baseline performance (mean prediction):\n",
      "Baseline RMSE (log scale): 0.4106\n",
      "Baseline RMSE (original scale): 75,775\n",
      "Mean log target: 12.0234\n",
      "Mean original target: 166,602\n",
      "\n",
      "RandomForest baseline (reproducing NB03):\n",
      "RandomForest RMSE (log scale): 0.1396\n",
      "Performance range: 0.41 (mean) to 0.1396 (RandomForest)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and targets (use both original and log-transformed)\n",
    "X_train = df_train_engineered[feature_cols]\n",
    "y_train_original = df_train_engineered['SalePrice']\n",
    "y_train_log = df_train_engineered['SalePrice_log']  # Primary target from NB03\n",
    "X_test = df_test_engineered[feature_cols]\n",
    "\n",
    "print(f\"Feature matrix shapes:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_train_original: {y_train_original.shape}\")\n",
    "print(f\"y_train_log: {y_train_log.shape} (primary target - pre-optimized)\")\n",
    "\n",
    "# Create train/validation split for model development (consistent seed)\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train, y_train_log, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain/validation split:\")\n",
    "print(f\"X_train_split: {X_train_split.shape}\")\n",
    "print(f\"X_val_split: {X_val_split.shape}\")\n",
    "print(f\"y_train_split: {y_train_split.shape}\")\n",
    "print(f\"y_val_split: {y_val_split.shape}\")\n",
    "\n",
    "# Baseline performance using simple mean prediction\n",
    "baseline_pred_log = np.full(len(y_val_split), y_train_split.mean())\n",
    "baseline_rmse_log = np.sqrt(mean_squared_error(y_val_split, baseline_pred_log))\n",
    "\n",
    "# Convert predictions and targets to original scale for interpretable baseline\n",
    "baseline_pred_original = np.exp(baseline_pred_log)\n",
    "y_val_original = np.exp(y_val_split)\n",
    "baseline_rmse_original = np.sqrt(mean_squared_error(y_val_original, baseline_pred_original))\n",
    "\n",
    "print(f\"\\nBaseline performance (mean prediction):\")\n",
    "print(f\"Baseline RMSE (log scale): {baseline_rmse_log:.4f}\")\n",
    "print(f\"Baseline RMSE (original scale): {baseline_rmse_original:,.0f}\")\n",
    "print(f\"Mean log target: {y_train_split.mean():.4f}\")\n",
    "print(f\"Mean original target: {np.exp(y_train_split.mean()):,.0f}\")\n",
    "\n",
    "# Scale features for consistency\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_split)\n",
    "\n",
    "# RandomForest baseline (matching notebook 03 exactly)\n",
    "rf_baseline = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "rf_cv_scores = cross_val_score(rf_baseline, X_train_scaled, y_train_split, cv=3,\n",
    "                              scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "rf_rmse_log = np.sqrt(-rf_cv_scores.mean())\n",
    "\n",
    "print(f\"\\nRandomForest baseline (reproducing NB03):\")\n",
    "print(f\"RandomForest RMSE (log scale): {rf_rmse_log:.4f}\")\n",
    "print(f\"Performance range: 0.41 (mean) to {rf_rmse_log:.4f} (RandomForest)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
